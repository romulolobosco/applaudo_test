{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "428f1f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "685ae26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/24 19:16:41 WARN Utils: Your hostname, c189 resolves to a loopback address: 127.0.1.1; using 192.168.0.133 instead (on interface wlp0s20f3)\n",
      "22/03/24 19:16:41 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/romulo.lobosco/Documents/pessoal/Applaudo/venv/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/03/24 19:16:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3446ca3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = \"ORDER_ID string, USER_ID string, ORDER_NUMBER string, ORDER_DOW integer, ORDER_HOUR_OF_DAY integer, DAYS_SINCE_PRIOR_ORDER float, ORDER_DETAIL string\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4f15c193",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"sample-datasets/*.csv\", header=True, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e323bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "eeff71bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96621"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2bf4ff71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    df\n",
    "    .withColumn(\n",
    "        \"ORDER_DETAIL\"\n",
    "        , F.split(F.col(\"ORDER_DETAIL\"), \"~\")\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"temp\"\n",
    "        , F.explode(F.col(\"ORDER_DETAIL\"))\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"product\"\n",
    "        , F.split(\"temp\", \"\\\\|\")[0]\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"aisles\"\n",
    "        , F.split(\"temp\", \"\\\\|\")[1]\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"sequential\"\n",
    "        , F.split(\"temp\", \"\\\\|\")[2]\n",
    "    )\n",
    "    .drop(\"ORDER_DETAIL\", \"temp\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6353b6ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1021748"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8457f13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "aa5652ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+------------+---------+-----------------+----------------------+--------------------+--------------------+----------+\n",
      "|ORDER_ID|USER_ID|ORDER_NUMBER|ORDER_DOW|ORDER_HOUR_OF_DAY|DAYS_SINCE_PRIOR_ORDER|             product|              aisles|sequential|\n",
      "+--------+-------+------------+---------+-----------------+----------------------+--------------------+--------------------+----------+\n",
      "| 1000867| 198377|           5|        0|               14|                   9.0|Triscuit Baked Wh...|            crackers|         8|\n",
      "| 1000867| 198377|           5|        0|               14|                   9.0|Nutter Butter Coo...|       cookies cakes|        10|\n",
      "| 1000867| 198377|           5|        0|               14|                   9.0|    Chili With Beans|  canned meals beans|         6|\n",
      "| 1000867| 198377|           5|        0|               14|                   9.0|Zingers Raspberry...|       cookies cakes|         6|\n",
      "| 1000867| 198377|           5|        0|               14|                   9.0|        Ho Hos Cakes|       cookies cakes|        13|\n",
      "| 1000867| 198377|           5|        0|               14|                   9.0|Small Curd Cottag...|other creams cheeses|        14|\n",
      "| 1000867| 198377|           5|        0|               14|                   9.0| Original Corn Chips|      chips pretzels|        14|\n",
      "| 1000867| 198377|           5|        0|               14|                   9.0|Original Citrus S...|         soft drinks|        13|\n",
      "|  100258| 156548|          29|        0|               23|                  15.0|Stage 2 Spinach, ...|   baby food formula|        12|\n",
      "|  100258| 156548|          29|        0|               23|                  15.0| Colby Cheese Sticks|     packaged cheese|         2|\n",
      "+--------+-------+------------+---------+-----------------+----------------------+--------------------+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c82ea4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56191bfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6c5b204d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+---+\n",
      "|ORDER_ID|product|rnk|\n",
      "+--------+-------+---+\n",
      "+--------+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    with temp as (select\n",
    "        ORDER_ID\n",
    "        , product\n",
    "        , rank() over(partition by ORDER_ID, product order by sequential) rnk\n",
    "    from t1)\n",
    "    select *\n",
    "    from temp\n",
    "    where rnk <> 1\n",
    "\"\"\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7e92cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "be11b52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"t1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e06900e",
   "metadata": {},
   "source": [
    "# The comparison between the aisles with the most products versus the best-selling product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e101ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a4d96dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 110:========>                                                (1 + 6) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------+\n",
      "|             aisles|tot_products|\n",
      "+-------------------+------------+\n",
      "|             yogurt|         889|\n",
      "|    candy chocolate|         875|\n",
      "|      ice cream ice|         857|\n",
      "|     chips pretzels|         816|\n",
      "|            missing|         800|\n",
      "|    packaged cheese|         776|\n",
      "|       frozen meals|         724|\n",
      "|energy granola bars|         668|\n",
      "|                tea|         632|\n",
      "|      juice nectars|         617|\n",
      "+-------------------+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    with product_order as (\n",
    "        select\n",
    "            distinct\n",
    "            product\n",
    "            , aisles\n",
    "        from t1\n",
    "    )\n",
    "    select\n",
    "        aisles\n",
    "        , count(product) tot_products\n",
    "    from product_order\n",
    "    group by aisles\n",
    "    order by tot_products desc\n",
    "    limit 10\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3c0cbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6c3bdedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 105:==========================================>              (6 + 2) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+--------------------------+-----+\n",
      "|product               |aisles                    |sails|\n",
      "+----------------------+--------------------------+-----+\n",
      "|Banana                |fresh fruits              |14022|\n",
      "|Bag of Organic Bananas|fresh fruits              |11553|\n",
      "|Organic Strawberries  |fresh fruits              |8156 |\n",
      "|Organic Baby Spinach  |packaged vegetables fruits|7349 |\n",
      "|Large Lemon           |fresh fruits              |6030 |\n",
      "|Organic Avocado       |fresh fruits              |5605 |\n",
      "|Organic Hass Avocado  |fresh fruits              |5451 |\n",
      "|Strawberries          |fresh fruits              |4857 |\n",
      "|Limes                 |fresh fruits              |4481 |\n",
      "|Organic Raspberries   |packaged vegetables fruits|4094 |\n",
      "+----------------------+--------------------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    with product_order as (\n",
    "        select\n",
    "            distinct\n",
    "            ORDER_ID\n",
    "            , product\n",
    "            , aisles\n",
    "        from t1\n",
    "    )\n",
    "    select\n",
    "        product\n",
    "        , aisles\n",
    "        , count(*) sails\n",
    "    from product_order\n",
    "    group by product, aisles\n",
    "    order by sails desc\n",
    "    limit 10\n",
    "\"\"\").show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdd44a2",
   "metadata": {},
   "source": [
    "# The top ten best selling products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5ef9ec20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 96:=================================>                        (4 + 3) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+-----+\n",
      "|product               |sails|\n",
      "+----------------------+-----+\n",
      "|Banana                |14022|\n",
      "|Bag of Organic Bananas|11553|\n",
      "|Organic Strawberries  |8156 |\n",
      "|Organic Baby Spinach  |7349 |\n",
      "|Large Lemon           |6030 |\n",
      "|Organic Avocado       |5605 |\n",
      "|Organic Hass Avocado  |5451 |\n",
      "|Strawberries          |4857 |\n",
      "|Limes                 |4481 |\n",
      "|Organic Raspberries   |4094 |\n",
      "+----------------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 98:>                                                         (0 + 8) / 8]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    with product_order as (\n",
    "        select\n",
    "            distinct\n",
    "            ORDER_ID\n",
    "            , product\n",
    "        from t1\n",
    "    )\n",
    "    select\n",
    "        product\n",
    "        , count(*) sails\n",
    "    from product_order\n",
    "    group by product\n",
    "    order by sails desc\n",
    "    limit 10\n",
    "\"\"\").show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9f1ab6",
   "metadata": {},
   "source": [
    "# The days of the week with the highest number of orders processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "997b59fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+\n",
      "|ORDER_DOW|total_per_day|\n",
      "+---------+-------------+\n",
      "|        0|        27465|\n",
      "|        1|        19672|\n",
      "|        5|        17401|\n",
      "|        2|        16103|\n",
      "|        4|        15959|\n",
      "|     null|           21|\n",
      "+---------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    with orders_week_day as (\n",
    "        select\n",
    "            distinct\n",
    "            ORDER_ID\n",
    "            , ORDER_DOW\n",
    "        from t1\n",
    "    )\n",
    "    select\n",
    "        ORDER_DOW\n",
    "        , count(*) total_per_day\n",
    "    from orders_week_day\n",
    "    group by ORDER_DOW\n",
    "    order by total_per_day desc\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e970e21",
   "metadata": {},
   "source": [
    "# View the number of orders per day and hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "58a98f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 75:=========================================>                (5 + 2) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------+---------------+\n",
      "|ORDER_DOW|ORDER_HOUR_OF_DAY|total_of_orders|\n",
      "+---------+-----------------+---------------+\n",
      "|        0|               24|              1|\n",
      "|        0|               23|            315|\n",
      "|        0|               22|            505|\n",
      "|        0|               21|            650|\n",
      "|        0|               20|            811|\n",
      "|        0|               19|           1042|\n",
      "|        0|               18|           1408|\n",
      "|        0|               17|           1800|\n",
      "|        0|               16|           2243|\n",
      "|        0|               15|           2518|\n",
      "|        0|               14|           2593|\n",
      "|        0|               13|           2417|\n",
      "|        0|               12|           2415|\n",
      "|        0|               11|           2354|\n",
      "|        0|               10|           2245|\n",
      "|        0|                9|           1774|\n",
      "|        0|                8|           1222|\n",
      "|        0|                7|            567|\n",
      "|        0|                6|            116|\n",
      "|        0|                5|             66|\n",
      "+---------+-----------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    with orders_week_day as (\n",
    "        select\n",
    "            distinct\n",
    "            ORDER_ID\n",
    "            , ORDER_DOW\n",
    "            , ORDER_HOUR_OF_DAY\n",
    "        from t1\n",
    "        where\n",
    "            True\n",
    "            and ORDER_DOW is not null\n",
    "            and ORDER_HOUR_OF_DAY is not null\n",
    "    )\n",
    "    select\n",
    "        ORDER_DOW\n",
    "        , ORDER_HOUR_OF_DAY\n",
    "        , count(*) total_of_orders\n",
    "    from orders_week_day\n",
    "    group by ORDER_DOW, ORDER_HOUR_OF_DAY\n",
    "    order by ORDER_DOW, ORDER_HOUR_OF_DAY desc\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f4e916",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78f5500",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa173327",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
